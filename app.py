import os
import re
import streamlit as st
import numpy as np
import pandas as pd
from PIL import Image, ImageDraw, ImageFont
from io import BytesIO
import easyocr
from transformers import BlipProcessor, BlipForConditionalGeneration
import torch

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ì´ë¯¸ì§€ ê¸°ë°˜ PDP ìë™í™”", layout="centered")
st.markdown("""
<style>
  .main .block-container {
    max-width: 1000px !important;
    margin: 0 auto !important;
  }
</style>
""", unsafe_allow_html=True)

# ëª¨ë¸ ë¡œë“œ
@st.cache_resource
def load_blip():
    proc = BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-base")
    mdl = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-base")
    return proc, mdl

@st.cache_resource
def load_easyocr_reader():
    return easyocr.Reader(['en'], gpu=False)

processor, blip_model = load_blip()
reader = load_easyocr_reader()

# UI: ì´ë¯¸ì§€ ì—…ë¡œë“œ
st.title("ì´ë¯¸ì§€ ê¸°ë°˜ PDP ìƒì„± ìë™í™” ì†”ë£¨ì…˜")
uploaded = st.file_uploader("ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["png","jpg","jpeg"])
if not uploaded:
    st.info("ì´ë¯¸ì§€ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”")
    st.stop()

img = Image.open(uploaded).convert("RGB")
annotated = img.copy()
draw = ImageDraw.Draw(annotated)
font = ImageFont.load_default()
draw.text((10, 10), "1", fill="red", font=font)
st.image(annotated, use_container_width=True)

# EasyOCR í…ìŠ¤íŠ¸ ì¶”ì¶œ
def extract_text_via_easyocr(pil_img: Image.Image) -> str:
    arr = np.array(pil_img)
    lines = reader.readtext(arr, detail=0, paragraph=True)
    return "\n".join(lines)

# BLIP ìº¡ì…˜ ìƒì„±
def generate_blip_caption(pil_img):
    device = "cuda" if torch.cuda.is_available() else "cpu"
    inputs = processor(images=pil_img, return_tensors="pt").to(device)
    blip_model.to(device)
    out = blip_model.generate(**inputs, max_length=50)
    return processor.decode(out[0], skip_special_tokens=True)

# Alt í›„ë³´ ìƒì„±
def make_alt_candidates(pil_img):
    base = generate_blip_caption(pil_img)
    cands = [base, base + " in a modern environment", "LG product - " + base]
    # ê³ ìœ í•˜ê²Œ ìµœëŒ€ 3ê°œ
    unique = []
    for c in cands:
        if c not in unique:
            unique.append(c)
        if len(unique) == 3:
            break
    return unique

# ë¶„ë¥˜/ì¶”ì²œ ì •ì˜
COMPONENT_DEFS = {
    "ST0001": {"name": "Hero banner", "has_image": True},
    "ST0002": {"name": "Tab Anchor", "has_image": False},
    "ST0003": {"name": "Title", "has_image": False},
    "ST0013": {"name": "Side Image", "has_image": True},
    "ST0014": {"name": "Layered Text", "has_image": True},
}

CTA_KEYWORDS = [
    "learn more","shop now","buy now","see more","read more",
    "click here","get started","try now","explore","discover","buy it now"
]

def classify_elements(lines):
    extracted, cleaned = [], []
    for L in lines:
        line = L
        for kw in CTA_KEYWORDS:
            if kw in line.lower():
                extracted.append(kw)
                line = re.sub(rf"\b{re.escape(kw)}\b", "", line, flags=re.IGNORECASE).strip()
        if line:
            cleaned.append(line)
    disclaimers = [l for l in cleaned if l.startswith("*")]
    body = [l for l in cleaned if not l.startswith("*")]
    ey = body.pop(0) if body and body[0].isupper() else ""
    hl = body.pop(0) if body else ""
    bc = "\n".join(body)
    return {"Eyebrow": ey, "Headline": hl, "Bodycopy": bc,
            "Disclaimer": "\n".join(disclaimers),
            "CTA": (extracted[0] if extracted else "")}

def recommend_components(classified, has_image=True):
    return [cid for cid, comp in COMPONENT_DEFS.items() if comp["has_image"] == has_image]

# Alt Text ìƒì„±
if st.button("ğŸ–¼ï¸ Alt Text ìƒì„±"):
    st.session_state["candidates"] = make_alt_candidates(img)
if "candidates" in st.session_state:
    choice = st.radio("Alt Text í›„ë³´ ì„ íƒ:", st.session_state["candidates"], key="alt_choice")
    st.subheader("ğŸ–¼ï¸ Selected Alt Text")
    st.code(choice)

# OCR ì‹¤í–‰ (EasyOCR)
if st.button("ğŸš€ OCR ì‹¤í–‰ (EasyOCR)"):
    txt = extract_text_via_easyocr(img)
    lines = txt.split("\n")
    st.session_state["ocr_done"] = True
    st.session_state["ocr_text"] = txt
    st.session_state["classified"] = classify_elements(lines)
    st.session_state["recs"] = recommend_components(st.session_state["classified"])

# ê²°ê³¼ ë Œë”ë§
if st.session_state.get("ocr_done"):
    st.subheader("ğŸ“‹ OCR ê²°ê³¼")
    st.text_area("", st.session_state["ocr_text"], height=200)
    st.subheader("ğŸ“‘ í…ìŠ¤íŠ¸ ë¶„ë¥˜ ê²°ê³¼")
    for k, v in st.session_state["classified"].items():
        st.markdown(f"**{k}:** {v or 'â€”'}")
    with st.expander("ğŸ§© ì»´í¬ë„ŒíŠ¸ ì¶”ì²œ"):
        recs = st.session_state["recs"]
        if recs:
            sel = st.selectbox("ì¶”ì²œëœ ì»´í¬ë„ŒíŠ¸ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì„¸ìš”:", recs,
                               format_func=lambda cid: f"{cid} â€“ {COMPONENT_DEFS[cid]['name']}")
            st.markdown(f"**Selected Component:** {sel} â€“ {COMPONENT_DEFS[sel]['name']}")
            st.session_state["selected_component"] = sel
        else:
            st.write("ì¶”ì²œí•  ì»´í¬ë„ŒíŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
    df = pd.DataFrame.from_dict(st.session_state["classified"], orient='index', columns=['Content'])
    csv = df.to_csv(encoding='utf-8-sig')
    st.download_button("ğŸ’¾ ì—‘ì…€ íŒŒì¼ ë‹¤ìš´ë¡œë“œ", data=csv, file_name="ocr_result.csv", mime="text/csv")

# ì „ì†¡ ê¸°ëŠ¥
if st.session_state.get("ocr_done") and st.button("ğŸ“¤ PDPìƒì„±í•˜ê¸° (WCMìœ¼ë¡œ ì „ì†¡í•˜ê¸°)"):
    st.caption("â€» í•´ë‹¹ ê¸°ëŠ¥ì€ ê¸°íš ë‹¨ê³„ì˜ êµ¬í˜„ì´ë©° ì‹¤ì œ ì ìš©ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
